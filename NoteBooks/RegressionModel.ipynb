{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Datasets : Case Report details , NPS Survey\n",
    "Input : Customer Case History\n",
    "Output : Healthscore for each account\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append(\"../src/TrainPipelines/\")\n",
    "\n",
    "from Preprocessing.RecordAgreement import RecordAgreement\n",
    "from Preprocessing.RemoveOutliers import RemoveOutliers\n",
    "from Preprocessing.FillingMissingVlaues import FillingMissingValues\n",
    "from Preprocessing.Labeling import Labeling\n",
    "from Preprocessing.Encoder import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_excel('C:/Users/gimhanSandeeptha/Gimhan Sandeeptha/Sentiment Project\\CustomerHealthScore\\Data\\sn_customerservice_case_report_1.xlsx')\n",
    "b = pd.read_csv('')\n",
    "c = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "warnings.filterwarnings('ignore')\n",
    "accountDataset = pd.read_excel('E:/Research/Datasets/WSO2/Original dataset/customer_account.xlsx')\n",
    "caseDataset    = pd.read_csv('E:/Research/Datasets/WSO2/Original dataset/Case Report/data_with_created_date/CaseReport.csv')\n",
    "nps            = pd.read_csv('E:/Research/Datasets/WSO2/Original dataset/NPS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseDataset.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseDataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nps.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustingDataset(df):\n",
    "    nps = df\n",
    "\n",
    "    # change feature names for ease of use\n",
    "    header_map = {\n",
    "        \"How likely are you to recommend WSO2 to a friend_ or colleague on a scale from 0 to 10? [0 being not at all likely and 10 being extremely likely]\":'likely_to_recomend',\n",
    "        \"How satisfied are you with the support given by the WSO2 team?\":'satisfaction',\n",
    "        \"Which response best captures the main impact of our product?\":'product_impact',\n",
    "        \"How responsive have we been to your questions or concerns about our products?\":'responsiveness'\n",
    "    }\n",
    "    nps.rename(columns=header_map,inplace=True)\n",
    "\n",
    "\n",
    "    # drop the columns that have many null values\n",
    "    temp_d1 = nps[['Account Name', 'Account Manager Name', 'UserName',\n",
    "            'UserID', 'ResponseID',  'timeStamp',\n",
    "        'dateTime',  'country',  'completion',\n",
    "        'likely_to_recomend',\n",
    "        'satisfaction',\n",
    "        'responsiveness',\n",
    "        'product_impact',\n",
    "        'Sales Region', 'Sub Region', 'Survey Campaign', 'Segment']]\n",
    "\n",
    "\n",
    "    # Filling missing values in Sales Region\n",
    "    temp_d2 = temp_d1\n",
    "    RegionMAP = np.load('../Data/Region_Map.npy',allow_pickle='TRUE').item()           # Region Map\n",
    "    temp_d2['Sales Region'] = temp_d2['Sales Region'].fillna(temp_d2['Sub Region'].map(RegionMAP))\n",
    "    return temp_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcrPercantage(col):\n",
    "    true_count  = col.sum()\n",
    "    total_count = len(col)\n",
    "    percentage_true = (true_count / total_count) * 100\n",
    "    return percentage_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChunkofData(df,start='2022-02-01',end='2022-08-01'):\n",
    "    df['Created'] = pd.to_datetime(df['Created'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    start_date  = pd.to_datetime(start)\n",
    "    end_date    = pd.to_datetime(end)\n",
    "\n",
    "    filtered_df = df[(df['Created'] >= start_date) & (df['Created'] <= end_date)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChunksBy6Months(df, start='2022-02-01', end='2022-08-01'):\n",
    "    start_date = pd.to_datetime(start)\n",
    "    end_date = pd.to_datetime(end)\n",
    "    six_months = pd.DateOffset(months=6)\n",
    "\n",
    "    chunks = []\n",
    "    while start_date < end_date:\n",
    "        chunk_end_date = start_date + six_months\n",
    "        if chunk_end_date > end_date:\n",
    "            chunk_end_date = end_date\n",
    "        chunk = getChunkofData(df=df, start=start_date, end=chunk_end_date)\n",
    "        chunks.append(chunk)\n",
    "        start_date += six_months\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getaggregatedList(df_list):\n",
    "    agg_list = []\n",
    "    for df in df_list:\n",
    "        agg_methods = {\n",
    "        'Time To Resolve': 'mean',   \n",
    "        'Agent Reassignment Count': 'mean',     \n",
    "        'First Contact Resolution': fcrPercantage,\n",
    "        'Reopen Count':'mean'\n",
    "        \n",
    "        }\n",
    "        accountWiseCaseDataset = df.groupby('Account').agg(agg_methods)\n",
    "        accountWiseCaseDataset = accountWiseCaseDataset.reset_index()\n",
    "        agg_list.append(accountWiseCaseDataset)\n",
    "    return agg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNPSbySurveys(df):\n",
    "    dataset   =  df[['Account Name','encoded_product_impact','healthScore','Survey Campaign','Sales Region','Sub Region','completion']]\n",
    "    dataset['Survey Campaign'] = pd.to_datetime(dataset['Survey Campaign'], format='%Y-%b')\n",
    "\n",
    "    dfs = []\n",
    "    for date, group in dataset.groupby('Survey Campaign'):\n",
    "        dfs.append(group)\n",
    "\n",
    "    mean_dfs = []\n",
    "    for df in dfs:\n",
    "        mean_df = df.groupby('Account Name').mean()\n",
    "        mean_df = mean_df.reset_index()\n",
    "        mean_dfs.append(mean_df)\n",
    "    return mean_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatanateData(tables,nps_list):\n",
    "    datasets = []\n",
    "    for df,nps in zip(tables,nps_list):\n",
    "        if isinstance(nps,pd.DataFrame):\n",
    "            concat_data   = pd.merge(df, nps[['Account Name','encoded_product_impact','Sales Region','Sub Region','completion','healthScore']], left_on='Account', right_on='Account Name', how='inner')\n",
    "            datasets.append(concat_data)\n",
    "        elif nps == None:concat_data  = concatenated_df\n",
    "\n",
    "    concatenated_df = pd.concat(datasets, ignore_index=True)\n",
    "    return concatenated_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model (Filling missing values in is_fcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Correlation of features'''\n",
    "import warnings\n",
    "import itertools\n",
    "import researchpy as rp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "df               = caseDataset.drop(['Unnamed: 0'],axis=1).copy()\n",
    "combinations     = list(itertools.combinations(df.dropna().columns, 2))\n",
    "cramers_v_values = pd.DataFrame(index=df.columns, columns=df.dropna().columns)\n",
    "\n",
    "# Calculate Cramér's V for each pair\n",
    "for feature1, feature2 in combinations:\n",
    "    crosstab, results                           = rp.crosstab(df.dropna()[feature1], df.dropna()[feature2], test='chi-square')\n",
    "    cramers_v_values.loc[feature1, feature2]    = results.loc[2, 'results']\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Create a heatmap\n",
    "cramers_v_values = cramers_v_values.apply(pd.to_numeric)\n",
    "plt.figure(figsize=(10,10))\n",
    "sn.heatmap(cramers_v_values, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title(\"Cramér's V Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseDataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "temp = caseDataset.copy()\n",
    "temp['First Contact Resolution']   = label_encoder.fit_transform(caseDataset['First Contact Resolution'])\n",
    "\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[['First Contact Resolution','Time To Resolve','Agent Reassignment Count','Reopen Count']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creatting model'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = caseDataset.dropna()\n",
    "\n",
    "X = df[['Time To Resolve']]\n",
    "y = df[['First Contact Resolution']]\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "y['First Contact Resolution']   = label_encoder.fit_transform(y['First Contact Resolution'])\n",
    "\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "score =accuracy_score(Y_test,y_pred)\n",
    "print(\"Accuracy:- \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'E:/Research/CHS_Repo/CustomerHealthScoreB2B/Models/Imputation_Model/fcrimputationModel_v2.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Clean Datasets #\n",
    "Input :accountDataset , caseDataset, nps\n",
    "Output: accountDataset2 ,filledcaseDataset ,labeledDataset\n",
    "'''\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "'''NPS Dataset'''\n",
    "# Get encoded dataframe\n",
    "temp_d2 =  adjustingDataset(nps)\n",
    "encode  = Encoder(temp_d2)\n",
    "temp_d3 =   encode.customEncoder()\n",
    "\n",
    "# Get agreement between records\n",
    "agreement       = RecordAgreement(temp_d3)                             # create an object of RecordAgreement class\n",
    "highAgreementdf =  agreement.gethighAgreementSurveys() \n",
    "\n",
    "# Remove outliers\n",
    "temp_df1    = highAgreementdf\n",
    "outlierObj  =  RemoveOutliers(temp_df1)\n",
    "filtered_df = outlierObj.removeOutliers()\n",
    "\n",
    "# Filling missing values\n",
    "temp_df2    = filtered_df\n",
    "fm          = FillingMissingValues(temp_df2,None)\n",
    "filled_df,_  = fm.getFilledDataset()\n",
    "\n",
    "# Labeling nps dataset\n",
    "labeling        =  Labeling(filled_df)\n",
    "labeledDataset  =  labeling.returnLabeleddf()\n",
    "\n",
    "temp = labeledDataset.copy()\n",
    "columns = ['completion','Sales Region','Sub Region']\n",
    "for col in columns:\n",
    "    label_encoder = preprocessing.LabelEncoder() \n",
    "    temp[col]  = label_encoder.fit_transform(temp[col])\n",
    "    label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    print(label_mapping)\n",
    "encoded_dataset = temp\n",
    "\n",
    "'''Account Datasets'''\n",
    "\n",
    "accountDataset2 = accountDataset.drop(['Support Tier'],axis=1)\n",
    "RegionMAP = np.load('../Data/Region_Map.npy',allow_pickle='TRUE').item()           # Region Map\n",
    "accountDataset2['Sales Region'] = accountDataset2['Sales Region'].fillna(accountDataset2['Sub Region'].map(RegionMAP))\n",
    "accountDataset2 = accountDataset2.drop_duplicates(subset=['Name(name)'])\n",
    "accountDataset2 = accountDataset2.dropna(subset=['Sub Region','Sales Region'])\n",
    "\n",
    "'''Case Dataset'''\n",
    "\n",
    "# Filling missing values\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "filename = 'E:/Research/CHS_Repo/CustomerHealthScoreB2B/Models/Imputation_Model/fcrimputationModel.pkl'\n",
    "model = pickle.load(open(filename, 'rb'))\n",
    "temp_df = caseDataset.copy()\n",
    "\n",
    "def custom_encode(boolean_value):\n",
    "    if pd.isnull(boolean_value):\n",
    "        return boolean_value\n",
    "    else:\n",
    "        return 1 if boolean_value else 0\n",
    "temp_df['First Contact Resolution'] = temp_df['First Contact Resolution'].map(custom_encode)\n",
    "\n",
    "\n",
    "X_missing = temp_df[temp_df['First Contact Resolution'].isnull()][['Time To Resolve']]\n",
    "predicted_values = model.predict(X_missing)\n",
    "\n",
    "filledcaseDataset = temp_df.drop(['Unnamed: 0'],axis=1).copy()\n",
    "filledcaseDataset.loc[filledcaseDataset['First Contact Resolution'].isnull(), 'First Contact Resolution'] = predicted_values\n",
    "filledcaseDataset = filledcaseDataset.dropna(subset=['Account'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filledcaseDataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Cleaning Account Names'''\n",
    "import re\n",
    "\n",
    "caseReportTable = filledcaseDataset.copy()\n",
    "\n",
    "def clean_account_name(account_name):\n",
    "    cleaned_name = re.sub(r'^(?:ZZZ:LOST\\s?--?|ZZZ:LOST\\s?-\\s?|ZZZ: LOST--\\s?|ZZZ: Lost - |ZZZ:Lost - |ZZZ:Lost -- |\\d{4}-\\d{2}-\\d{2}-?\\s?)', '', account_name)\n",
    "    return cleaned_name.strip()\n",
    "\n",
    "caseReportTable['Account'] = caseReportTable['Account'].apply(clean_account_name)\n",
    "caseReportTable['Account'] = caseReportTable['Account'].apply(clean_account_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Report\n",
    "'''Aggregate the data in case report'''\n",
    "\n",
    "datasets = getChunksBy6Months(df=caseReportTable,start='2021-08-01',end='2024-02-01')\n",
    "tempdfs = getaggregatedList(datasets)\n",
    "nps_list = getNPSbySurveys(df=encoded_dataset)\n",
    "dataset  = concatanateData(tempdfs,nps_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = dataset[['Time To Resolve', 'Agent Reassignment Count',\n",
    "            'First Contact Resolution', 'Reopen Count', \n",
    "        'encoded_product_impact', 'Sales Region', 'Sub Region', 'completion']]\n",
    "y = dataset['healthScore']\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X, y)\n",
    "\n",
    "explainer = shap.Explainer(model, X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "shap.summary_plot(shap_values, X)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X = dataset[['Time To Resolve', 'Agent Reassignment Count',\n",
    "            'First Contact Resolution', 'Reopen Count', \n",
    "        'encoded_product_impact', 'Sales Region', 'Sub Region', 'completion']]\n",
    "y = dataset['healthScore']\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X, y)\n",
    "\n",
    "explainer = shap.LinearExplainer(model, X)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# Visualize the relationship between input variables and target variable using line charts\n",
    "for index in range(len(X.columns)):\n",
    "    shap.dependence_plot(int(index), shap_values.values, X,show=False)\n",
    "    plt.title(f'Relationship between {X.columns[index]} and Target Variable')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergedDf.drop(['Survey Campaign','Account'],axis=1).to_csv('E:/Research/CHS_Repo/CustomerHealthScoreB2B/Data/merged_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot histograms for each feature\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, column in enumerate(dataset.drop(['Account','Account Name'],axis=1).columns):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.histplot(dataset[column], kde=True) \n",
    "    plt.title(f'Distribution of {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = dataset.drop(['Account'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf.drop(['Account Name'],axis=1).corr(method='spearman')['healthScore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso,BayesianRidge                     \n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "X = trainDf.drop(columns=['healthScore','Account Name'])\n",
    "y = trainDf['healthScore']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Ridge(alpha=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "                'alpha': [0.000001,0.001,0.01,0.015, 0.1,0.6, 1.0, 10.0]\n",
    "            }\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "bestParams  = grid_search.best_params_\n",
    "bestParams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
