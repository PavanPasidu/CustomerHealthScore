{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get datasets\n",
    "import pandas as pd\n",
    "\n",
    "filepath    = 'E:/Research/Datasets/WSO2/Healthscore_dataset'\n",
    "nps         = pd.read_csv(filepath + '/NPS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change feature names for ease of use\n",
    "header_map = {\n",
    "    \"How likely are you to recommend WSO2 to a friend_ or colleague on a scale from 0 to 10? [0 being not at all likely and 10 being extremely likely]\":'likely_to_recomend',\n",
    "    \"How satisfied are you with the support given by the WSO2 team?\":'satisfaction',\n",
    "    \"Which response best captures the main impact of our product?\":'product_impact',\n",
    "    \"How responsive have we been to your questions or concerns about our products?\":'responsiveness'\n",
    "}\n",
    "\n",
    "nps.rename(columns=header_map,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######  view dataset ##############\n",
    "\n",
    "# print total null values in each column\n",
    "print('-----Null value count:-----\\n\\n',nps.isna().sum())\n",
    "\n",
    "# print unique values in each column\n",
    "print('\\n\\n--------Unique Value COunt-----------\\n\\n',nps.nunique())\n",
    "\n",
    "# drop the columns that have many null values\n",
    "temp_d1 = nps[['Account Name', 'Account Manager Name', 'UserName',\n",
    "        'UserID', 'ResponseID',  'timeStamp',\n",
    "       'dateTime',  'country',  'completion',\n",
    "       'likely_to_recomend',\n",
    "       'satisfaction',\n",
    "       'responsiveness',\n",
    "       'product_impact',\n",
    "       'Sales Region', 'Sub Region', 'Survey Campaign', 'Segment']]\n",
    "\n",
    "temp_d1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_d1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Filling missing values in Sales Region #####\n",
    "temp_d2 = temp_d1\n",
    "\n",
    "# create a map between Sub Region ---- Sales Region\n",
    "Sub_Regions = set(temp_d2['Sub Region'].tolist())\n",
    "Region_Map  = dict() \n",
    "\n",
    "for sub_r in Sub_Regions:\n",
    "    sales_r                 = temp_d2[(temp_d2['Sub Region']==sub_r)]['Sales Region'].unique()\n",
    "    if len(sales_r)==1:\n",
    "        Region_Map[sub_r]   = sales_r[0]\n",
    "    elif len(sales_r)>1:\n",
    "        print(sales_r)\n",
    "        print('Impossible to have more than one sales region for a sub region')\n",
    "    else:Region_Map[sub_r]  = None\n",
    "\n",
    "still_null_regions = ['NA - CENTRAL','NA - SOUTH','NA - WEST','NA - EAST']\n",
    "for region in still_null_regions:\n",
    "    Region_Map[region]      = 'NA'\n",
    "\n",
    "\n",
    "\n",
    "# Filling missing values in Sales Region\n",
    "temp_d2['Sales Region']     = temp_d2['Sales Region'].fillna(temp_d2['Sub Region'].map(Region_Map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Region_Map\n",
    "import numpy as np\n",
    "np.save('E:/Research/CHS_Repo/Region_Map.npy', Region_Map) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether there is any multiple responses from same account name\n",
    "\n",
    "surveys = []\n",
    "encoded_surveys =[]\n",
    "survey_dates = list(temp_d2['Survey Campaign'].unique())\n",
    "\n",
    "# encode dataset\n",
    "def custom_encoder(d1):\n",
    "     # ordinal encoding on features\n",
    "    encoder_map_1 = {\"Excellent\":5,\"Good\":4,\"Okay\":3,\"Bad\":2,\"Terrible\":1}\n",
    "    encoder_map_2 = {\"Excellent\":4,\"Good\":3,\"OK\":2,\"Slow\":1}\n",
    "    encoder_map_3 = {\"Many of the above\":9,\"High Quality\":8,\"Scalable\":7,\"Value for Money\":6,\"Useful\":5,\"Reliable\":4,\"Secure\":3,\"Unique\":2,\"None of the above\":1}\n",
    "\n",
    "    # --- satisfaction ----\n",
    "    d1['encoded_satisfaction'] = d1.satisfaction.map(encoder_map_1)\n",
    "    d1 = d1.drop(['satisfaction'],axis=1)\n",
    "\n",
    "    # --- responsiveness ---\n",
    "    d1['encoded_responsiveness'] = d1.responsiveness.map(encoder_map_2)\n",
    "    d1 = d1.drop(['responsiveness'],axis=1)\n",
    "\n",
    "    # --- product_impact ----\n",
    "    d1['encoded_product_impact'] = d1.product_impact.map(encoder_map_3)\n",
    "    d1 = d1.drop(['product_impact'],axis=1)\n",
    "    return d1\n",
    "\n",
    "for date in survey_dates:\n",
    "    d1 = temp_d2[(temp_d2['Survey Campaign'] == date)]\n",
    "    surveys.append(d1)\n",
    "\n",
    "    # print length of each datasets\n",
    "    print('Length of dataset - ',len(d1))\n",
    "\n",
    "    # check is there any  duplicate accounts\n",
    "    print('Duplicated\\n') if True in d1[['Account Name']].duplicated().values else None\n",
    "\n",
    "    # encode surveys\n",
    "    d2 = custom_encoder(d1)\n",
    "    encoded_surveys.append(d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See duplicate record\n",
    "temp_d2 = temp_d2.drop_duplicates()\n",
    "print(temp_d2.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the duplicated account name list\n",
    "i=2022\n",
    "count=0\n",
    "duplicate_acoounts = dict()\n",
    "for survey in surveys:\n",
    "    temp = []\n",
    "    for true_val,account in zip(survey[['Account Name']].duplicated(),survey['Account Name']):\n",
    "        if true_val:\n",
    "            temp.append(account)\n",
    "            duplicate_acoounts[i] = temp\n",
    "\n",
    "            print('ID : ',i,account)\n",
    "            count+= 1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of dupclicated accounts\n",
    "print(count)\n",
    "print(duplicate_acoounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now i need to measure consensus(agreement) between records of duplicate account name \n",
    "# Here I am using Krippendorff's alpha method\n",
    "\n",
    "'''\n",
    "Here in Fleiss Kappa and Krippendorff's alpha what we are doing is if we have multiple raters in our scenario multiple responders,\n",
    "we measure the agreement between multiple responses.\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the agreement of duplicate responses\n",
    "import krippendorff as kd\n",
    "\n",
    "Krippendorff_dic    = dict()    # dictionary to store Krippendorff's alpha values\n",
    "index               = 2022\n",
    "\n",
    "for survey in encoded_surveys:                                                                         # add survey no as key\n",
    "    accs                = survey['Account Name']\n",
    "    duplicated_acc_list = list(survey[accs.isin(accs[accs.duplicated()])]['Account Name'].to_list())   # get names of account names which are duplicated\n",
    "    temp_dic            = dict()\n",
    "    \n",
    "    \n",
    "    for account in set(duplicated_acc_list):\n",
    "        df = survey[(survey['Account Name']==account)][['likely_to_recomend','encoded_satisfaction','encoded_responsiveness']]\n",
    "        df = df.fillna(-1)\n",
    "\n",
    "        if len(df)==0:\n",
    "            continue\n",
    "        \n",
    "        table               = df.values.tolist()\n",
    "\n",
    "        Krippendorff        = kd.alpha(table,level_of_measurement='ordinal')          # calculating Krippendorff's alpha\n",
    "        temp_dic[account]   = Krippendorff                                       # add Krippendorff to tempary dict\n",
    "    \n",
    "    Krippendorff_dic[index] = temp_dic \n",
    "    index+=1                                             # assign Krippendorff alpha of accounts in each survey\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Here I am considering low agreement data records as outliers. Since I can not decide which record is the outlier from multiple responses\n",
    "from single account, I am going to drop all the responses belongs to that account name.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique Account Names in each survey\n",
    "# get the propotion of duplicated accounts\n",
    "tot = 0\n",
    "for survey in encoded_surveys:\n",
    "    tot = tot+survey[['Account Name']].nunique()\n",
    "    print(survey[['Account Name']].duplicated().sum()*100/len(survey[['Account Name']])  , '%')\n",
    "\n",
    "print(tot,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### lets check how many will left after aggregating multiple responses  #######\n",
    "\n",
    "# calculate how many of Krippendorff alpha values have above 0.6 value\n",
    "keys = Krippendorff_dic.keys()\n",
    "for key in keys:\n",
    "    count=0\n",
    "    k_values = Krippendorff_dic[key].values()\n",
    "    for k in k_values:\n",
    "        if k>=0.6:count+=1\n",
    "    print('Krippendorff alpha value percentage with equal or more than 0.4 : \\n',count*100/len(k_values),'\\nTotal values:',len(k_values),\n",
    "          '\\n','Count : ',count,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "If we remove low agreement records we might loose lots of data records\n",
    "But here most of records have atleast average agreement between multiple responds\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillingRegions(d2,Region_Map):\n",
    "    d2['Sales Region'] = d2['Sales Region'].fillna(d2['Sub Region'].map(Region_Map))\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys                    = Krippendorff_dic.keys()\n",
    "high_agreement_surveys  = []\n",
    "for key,survey in zip(keys,encoded_surveys):\n",
    "    k_values    = Krippendorff_dic[key].values()        # getting Krippendorff alpha values of each multi responses\n",
    "    k_account   =    Krippendorff_dic[key].keys()       # getting country of each multi responses\n",
    "    survey      = fillingRegions(survey,Region_Map)     # filling missing sales region\n",
    "    for k,acc in zip(k_values,k_account):\n",
    "        if k<0.6:\n",
    "            duplicates      = survey[(survey['Account Name']==acc)]\n",
    "            print(duplicates[['likely_to_recomend','encoded_satisfaction', 'encoded_responsiveness', 'encoded_product_impact']])       # print low agrrement data\n",
    "            \n",
    "            survey          = survey.drop(survey[(survey['Account Name']==acc)].index)           # drop low agreement response\n",
    "    high_agreement_surveys.append(survey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no.of columns left\n",
    "c     =   0\n",
    "for i in range(5):\n",
    "    c = c + len(high_agreement_surveys[i])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the surveys \n",
    "merged_surveys     = high_agreement_surveys[0]\n",
    "\n",
    "for id in range(1,len(high_agreement_surveys)):\n",
    "    merged_surveys = pd.concat([merged_surveys,high_agreement_surveys[id]] , axis=0)\n",
    "\n",
    "merged_surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null values in each column\n",
    "merged_surveys.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Lets manually inspect for agreement of the data records'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = Krippendorff_dic.keys()\n",
    "\n",
    "for key,survey in zip(keys,encoded_surveys):\n",
    "    k_values    = Krippendorff_dic[key].values()       # getting Krippendorff alpha values of each multi responses\n",
    "    k_account   =    Krippendorff_dic[key].keys()     # getting country of each multi responses\n",
    "    survey      = fillingRegions(survey,Region_Map)      # filling missing sales region\n",
    "    for k,acc in zip(k_values,k_account):\n",
    "        if k>=0.6:\n",
    "            temp_survey = survey[(survey['Account Name']==acc)]         # get high agreement data\n",
    "            print(temp_survey[['likely_to_recomend','encoded_satisfaction', 'encoded_responsiveness', 'encoded_product_impact','dateTime']])     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the merged dataset\n",
    "merged_surveys.to_csv('E:/Research/Datasets/WSO2/Preprocessed datasets/higher_agreement_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Lets check outliers. Even though it is hard to identify'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df1 = merged_surveys\n",
    "\n",
    "# Define function to filter records based on likelihood to recommend mode\n",
    "def filter_records(group):\n",
    "    mode    = group['likely_to_recomend'].mode()\n",
    "    median  = group['likely_to_recomend'].median()\n",
    "    if len(mode) == 1:  \n",
    "        group['diff_to_mode'] = abs(group['likely_to_recomend'] - mode[0])\n",
    "        return group[group['diff_to_mode'] <= 5]\n",
    "    else:\n",
    "        group['diff_to_mode'] = abs(group['likely_to_recomend'] - median)\n",
    "        return group[group['diff_to_mode'] <= 5]\n",
    "\n",
    "\n",
    "filtered_df = temp_df1.groupby('Account Name').apply(filter_records)       # Apply the function to each group\n",
    "filtered_df = filtered_df.drop(columns=['diff_to_mode']).reset_index(drop=True)            # Remove extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the dataset after removing outliers\n",
    "print(\"Misssing value count of each feature:\\n \\n\",filtered_df.isna().sum(),\"\\n\\nUnique value count of each feature:\\n\",  max(filtered_df.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.to_csv('E:\\Research\\Datasets\\WSO2\\Preprocessed datasets/filtereddata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here what we are doing is we fill the missing values with account wise mode.\n",
    "But we are not going to fill missing values of accounts that hvae multiple modes. \n",
    "Here mode means column wise mode.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values of encoded_product_impact,encoded_responsiveness,encoded_satisfaction with mode,median\n",
    "\n",
    "temp_df = filtered_df\n",
    "\n",
    "# Define function to fill missing values with mode, excluding multiple modes\n",
    "def fill_missing(group):\n",
    "    for col in group[['encoded_satisfaction', 'encoded_responsiveness',\n",
    "       'encoded_product_impact']].columns:  \n",
    "        mode_values = group[col].mode()\n",
    "        median_values = group[col].median()\n",
    "        \n",
    "        if len(mode_values)     == 1:                               # Only fill if there's a single mode\n",
    "            group[col]      = group[col].fillna(mode_values[0])\n",
    "        elif len(mode_values)   ==2 and col!='encoded_product_impact':\n",
    "            group[col]      = group[col].fillna(mode_values.mean())\n",
    "        elif len(mode_values)   >=3 and col!='encoded_product_impact':\n",
    "            group[col]      = group[col].fillna(mode_values.median())\n",
    "        else:\n",
    "            if col!='encoded_product_impact':\n",
    "                group[col] = group[col].fillna(median_values)\n",
    "                \n",
    "    \n",
    "    return group\n",
    "\n",
    "# Apply the function to each group\n",
    "filled_df = temp_df.groupby('Account Name').apply(fill_missing).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at the dataset after filling missing values\n",
    "print(\"Misssing value count of each feature:\\n \\n\",filled_df.isna().sum(),\"\\n\\nUnique value count of each feature:\\n\",  max(filled_df.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records with missing values\n",
    "Cleaned_df = filled_df.dropna(subset=['encoded_responsiveness','encoded_satisfaction'])\n",
    "Cleaned_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.to_csv('E:/Research/Datasets/WSO2/Preprocessed datasets/filleddata.csv')\n",
    "# filtered_df.to_csv('E:/Research/Datasets/WSO2/Preprocessed datasets/cleaneddata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''ANother method is to handle missing value is dropping all the records with missing values'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let drop all the missing values\n",
    "# temp_d3 = temp_d2.dropna()\n",
    "# temp_d3.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the datasets\n",
    "Cleaned_df = Cleaned_df\n",
    "Filled_df = filled_df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "I can do labeling in two ways.\n",
    "    1. I can use cleaned dataset and get a weighted score as a label\n",
    "    2. I can use filled dataset which has null values and implement a method to labeling with null values\n",
    "        - I use three fields for labeling (likely to recommend us, responsiveness , satisfaction of our service)\n",
    "        - Only 2 contains null values (responsiveness , satisfaction of our service)\n",
    "\n",
    "\n",
    "        (let assume all three has scaled to 100,10,10 respectively)\n",
    "        Function to calculate healthscore label\n",
    "            - healthScore = likeley to recommend - ((responsiveness.max - responsiveness) + (satisfaction of our service.max - satisfaction of our service))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### calculate the label   ############\n",
    "\n",
    "labelFields     = Filled_df[['likely_to_recomend','encoded_satisfaction', 'encoded_responsiveness']]        # Get required fields\n",
    "weights         = [100,10,10]\n",
    "\n",
    "# Scale the field values\n",
    "for col,w in zip(labelFields.columns,weights):\n",
    "    labelFields[col] =  labelFields[col]*w/(labelFields[col].max() - labelFields[col].min())\n",
    "\n",
    "\n",
    "likely_to_recomend  =   labelFields['likely_to_recomend']\n",
    "satisfaction        =   labelFields['encoded_satisfaction']\n",
    "responsiveness      =   labelFields['encoded_responsiveness']\n",
    "Filled_df['healthScore'] = likely_to_recomend - ( (satisfaction.max()  -  satisfaction ) +( responsiveness.max()  -  responsiveness) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "import researchpy as rp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "df                  = Filled_df.copy()\n",
    "combinations        = list(itertools.combinations(df.dropna().columns, 2))\n",
    "cramers_v_values    = pd.DataFrame(index=df.columns, columns=df.dropna().columns)\n",
    "\n",
    "# Calculate Cramér's V for each pair\n",
    "for feature1, feature2 in combinations:\n",
    "    crosstab, results                           = rp.crosstab(df.dropna()[feature1], df.dropna()[feature2], test='chi-square')\n",
    "    cramers_v_values.loc[feature1, feature2]    = results.loc[2, 'results']\n",
    "    # print(f\"Cramér's V for {feature1} and {feature2}: {results.loc[2, 'results']}\")\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Create a heatmap\n",
    "cramers_v_values        = cramers_v_values.apply(pd.to_numeric)\n",
    "plt.figure(figsize=(15,15))\n",
    "sn.heatmap(cramers_v_values, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title(\"Cramér's V Heatmap\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
